{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0hnBzZr0IzAWJ8x+t9HUy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ShuffNet Modeli"],"metadata":{"id":"cZbvjiXtAvOl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONqOvLPYAdET","executionInfo":{"status":"ok","timestamp":1716897196666,"user_tz":-180,"elapsed":2326,"user":{"displayName":"Hacer Özcan","userId":"13717876665376904523"}},"outputId":"4ca12267-36f3-4d66-98ba-ef24dd3bab3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])"],"metadata":{"id":"EkQSQHAGA40i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Veri Seti 1 ait yol\n","train_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_1/train', transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","val_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_1/Validation', transform=transform)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","\n","test_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_1/test', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n"],"metadata":{"id":"1M8sOxcDA7Xs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hard_verisetinin yolu\n","train_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_hard/Train', transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","val_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_hard/Validation', transform=transform)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n","\n","test_dataset = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/Image_Processing/Veri_Setleri/veri_seti_hard/Test', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"],"metadata":{"id":"DgOHkpNxBZsl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 2)  # 2 sınıf sahte ve gerçek"],"metadata":{"id":"RvppIvN7BGHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"iAYZwEttBKRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return epoch_loss"],"metadata":{"id":"34a1Jsm_BND0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, val_loader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    accuracy = correct / total\n","    return accuracy"],"metadata":{"id":"3eKaVTysBPeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accuracies = []\n","val_accuracies = []\n","\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    val_accuracy = validate(model, val_loader, criterion, device)\n","    train_accuracies.append(train_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}\")"],"metadata":{"id":"l8sfOoR9BRms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test\n","def test(model, test_loader, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    accuracy = correct / total\n","    print(f\"Test Accuracy: {accuracy:.2f}\")\n","\n","test(model, test_loader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAIyCat4BUS_","executionInfo":{"status":"ok","timestamp":1716899523731,"user_tz":-180,"elapsed":3117,"user":{"displayName":"Hacer Özcan","userId":"13717876665376904523"}},"outputId":"2ec09385-747b-4254-8f7f-2b2b879914d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.92\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","'''\n","# Eğitim ve doğrulama doğruluklarını kaydetmek için boş listeler\n","train_accuracies = []\n","val_accuracies = []\n","\n","# Eğitim ve doğrulama döngüsü\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    val_accuracy = validate(model, val_loader, criterion, device)\n","\n","    # Doğrulukları listeye ekleme\n","    train_accuracies.append(val_accuracy)\n","    val_accuracies.append(val_accuracy)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}\")\n","'''\n","test(model, test_loader, device)\n","\n","plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Loss')\n","plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation ')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"-v4ZLimNB254"},"execution_count":null,"outputs":[]}]}